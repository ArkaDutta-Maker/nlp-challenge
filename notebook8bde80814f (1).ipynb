{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14509913,"sourceType":"datasetVersion","datasetId":9267548}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:20:25.374515Z","iopub.execute_input":"2026-01-15T17:20:25.374795Z","iopub.status.idle":"2026-01-15T17:20:27.170628Z","shell.execute_reply.started":"2026-01-15T17:20:25.374760Z","shell.execute_reply":"2026-01-15T17:20:27.170023Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!apt-get update && apt-get install -y libzbar0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:20:27.172339Z","iopub.execute_input":"2026-01-15T17:20:27.172829Z","iopub.status.idle":"2026-01-15T17:20:43.613104Z","shell.execute_reply.started":"2026-01-15T17:20:27.172796Z","shell.execute_reply":"2026-01-15T17:20:43.612235Z"}},"outputs":[{"name":"stdout","text":"Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\nGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \nGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \nGet:4 https://cli.github.com/packages stable InRelease [3,917 B]               \nGet:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]      \nGet:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nHit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\nHit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\nGet:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,637 kB]\nGet:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,289 kB]\nGet:13 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]          \nGet:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,600 kB]\nGet:15 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\nGet:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,968 kB]\nGet:17 https://cli.github.com/packages stable/main amd64 Packages [354 B]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\nGet:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,297 kB]\nGet:22 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\nGet:23 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,607 kB]\nGet:24 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,868 kB]\nFetched 32.3 MB in 3s (10.2 MB/s)                            \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  libv4l-0 libv4lconvert0\nThe following NEW packages will be installed:\n  libv4l-0 libv4lconvert0 libzbar0\n0 upgraded, 3 newly installed, 0 to remove and 128 not upgraded.\nNeed to get 248 kB of archives.\nAfter this operation, 831 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libv4lconvert0 amd64 1.22.1-2build1 [82.4 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libv4l-0 amd64 1.22.1-2build1 [44.9 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzbar0 amd64 0.23.92-4build2 [121 kB]\nFetched 248 kB in 1s (420 kB/s) \nSelecting previously unselected package libv4lconvert0:amd64.\n(Reading database ... 129073 files and directories currently installed.)\nPreparing to unpack .../libv4lconvert0_1.22.1-2build1_amd64.deb ...\nUnpacking libv4lconvert0:amd64 (1.22.1-2build1) ...\nSelecting previously unselected package libv4l-0:amd64.\nPreparing to unpack .../libv4l-0_1.22.1-2build1_amd64.deb ...\nUnpacking libv4l-0:amd64 (1.22.1-2build1) ...\nSelecting previously unselected package libzbar0:amd64.\nPreparing to unpack .../libzbar0_0.23.92-4build2_amd64.deb ...\nUnpacking libzbar0:amd64 (0.23.92-4build2) ...\nSetting up libv4lconvert0:amd64 (1.22.1-2build1) ...\nSetting up libv4l-0:amd64 (1.22.1-2build1) ...\nSetting up libzbar0:amd64 (0.23.92-4build2) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install --no-cache-dir \\\n  colpali-engine \\\n  chromadb \\\n  rank_bm25 \\\n  langchain \\\n  langchain-community \\\n  langchain-huggingface \\\n  langchain-groq \\\n  langchain-experimental \\\n  langgraph \\\n  pymupdf \\\n  pyzbar \\\n  accelerate \\\n  bitsandbytes \\\n  peft \\\n  pdf2image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:20:43.614365Z","iopub.execute_input":"2026-01-15T17:20:43.614686Z","iopub.status.idle":"2026-01-15T17:21:08.831574Z","shell.execute_reply.started":"2026-01-15T17:20:43.614644Z","shell.execute_reply":"2026-01-15T17:21:08.830653Z"}},"outputs":[{"name":"stdout","text":"Collecting colpali-engine\n  Downloading colpali_engine-0.3.13-py3-none-any.whl.metadata (32 kB)\nCollecting chromadb\n  Downloading chromadb-1.4.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\nCollecting rank_bm25\n  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\nCollecting langchain-community\n  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting langchain-huggingface\n  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting langchain-groq\n  Downloading langchain_groq-1.1.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain-experimental\n  Downloading langchain_experimental-0.4.1-py3-none-any.whl.metadata (1.3 kB)\nCollecting langgraph\n  Downloading langgraph-1.0.6-py3-none-any.whl.metadata (7.4 kB)\nCollecting pymupdf\n  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\nCollecting pyzbar\n  Downloading pyzbar-0.1.9-py2.py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\nRequirement already satisfied: pdf2image in /usr/local/lib/python3.12/dist-packages (1.17.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from colpali-engine) (2.0.2)\nRequirement already satisfied: pillow>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from colpali-engine) (11.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from colpali-engine) (2.32.5)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from colpali-engine) (1.15.3)\nRequirement already satisfied: torch<2.9.0,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from colpali-engine) (2.8.0+cu126)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from colpali-engine) (0.23.0+cu126)\nRequirement already satisfied: transformers<4.58.0,>=4.53.1 in /usr/local/lib/python3.12/dist-packages (from colpali-engine) (4.57.1)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\nRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.12.5)\nCollecting pybase64>=1.4.1 (from chromadb)\n  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\nCollecting posthog<6.0.0,>=2.4.0 (from chromadb)\n  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading pypika-0.50.0-py2.py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m258.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\nRequirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (33.1.0)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\nRequirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (14.2.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.37)\nCollecting SQLAlchemy<3,>=1.4 (from langchain)\n  Downloading sqlalchemy-2.0.45-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\nINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-community\n  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.36.0)\nINFO: pip is looking at multiple versions of langchain-huggingface to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-huggingface\n  Downloading langchain_huggingface-1.1.0-py3-none-any.whl.metadata (2.8 kB)\n  Downloading langchain_huggingface-1.0.1-py3-none-any.whl.metadata (2.1 kB)\n  Downloading langchain_huggingface-1.0.0-py3-none-any.whl.metadata (2.1 kB)\n  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\nCollecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\nINFO: pip is looking at multiple versions of langchain-groq to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-groq\n  Downloading langchain_groq-1.1.0-py3-none-any.whl.metadata (2.4 kB)\n  Downloading langchain_groq-1.0.1-py3-none-any.whl.metadata (2.4 kB)\n  Downloading langchain_groq-1.0.0-py3-none-any.whl.metadata (1.7 kB)\n  Downloading langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\nINFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-experimental\n  Downloading langchain_experimental-0.4.0-py3-none-any.whl.metadata (1.3 kB)\n  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\nCollecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph)\n  Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\nCollecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n  Downloading langgraph_prebuilt-1.0.6-py3-none-any.whl.metadata (5.2 kB)\nCollecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph)\n  Downloading langgraph_sdk-0.3.3-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.2.1rc0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.6.2)\nRequirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\nCollecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph)\n  Downloading ormsgpack-1.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nINFO: pip is looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\nCollecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n  Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n  Downloading langgraph_prebuilt-1.0.3-py3-none-any.whl.metadata (5.2 kB)\n  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\nCollecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph)\n  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\nINFO: pip is still looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n  Downloading langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\nCollecting pip>=25.2 (from langchain-text-splitters<1.0.0,>=0.3.9->langchain)\n  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\nCollecting langgraph\n  Downloading langgraph-1.0.5-py3-none-any.whl.metadata (7.4 kB)\n  Downloading langgraph-1.0.4-py3-none-any.whl.metadata (7.8 kB)\nCollecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n  Downloading langgraph_sdk-0.2.15-py3-none-any.whl.metadata (1.6 kB)\nCollecting langgraph\n  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\nCollecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph)\n  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\nRequirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.71.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\nCollecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->colpali-engine) (3.4.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (75.2.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.9.0,>=2.2.0->colpali-engine) (3.4.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58.0,>=4.53.1->colpali-engine) (2025.11.3)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.9.0,>=2.2.0->colpali-engine) (3.0.3)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\nDownloading colpali_engine-0.3.13-py3-none-any.whl (88 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/88.6 kB\u001b[0m \u001b[31m331.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chromadb-1.4.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m202.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\nDownloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m385.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\nDownloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\nDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m357.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m353.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m268.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\nDownloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m190.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pyzbar-0.1.9-py2.py3-none-any.whl (32 kB)\nDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m216.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m369.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading groq-0.37.1-py3-none-any.whl (137 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m283.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langgraph_sdk-0.2.15-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m248.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m302.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m296.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m355.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m244.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m341.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m334.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m311.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pypika-0.50.0-py2.py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m312.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sqlalchemy-2.0.45-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m266.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m391.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ormsgpack-1.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 kB\u001b[0m \u001b[31m342.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m272.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m376.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m263.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m282.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyzbar, pypika, uvloop, SQLAlchemy, rank_bm25, pymupdf, pybase64, ormsgpack, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, langgraph-sdk, groq, opentelemetry-sdk, bitsandbytes, opentelemetry-exporter-otlp-proto-grpc, langgraph-checkpoint, langchain-huggingface, langchain-groq, langgraph-prebuilt, colpali-engine, chromadb, langgraph, langchain-community, langchain-experimental\n  Attempting uninstall: SQLAlchemy\n    Found existing installation: SQLAlchemy 1.2.19\n    Uninstalling SQLAlchemy-1.2.19:\n      Successfully uninstalled SQLAlchemy-1.2.19\n  Attempting uninstall: opentelemetry-proto\n    Found existing installation: opentelemetry-proto 1.37.0\n    Uninstalling opentelemetry-proto-1.37.0:\n      Successfully uninstalled opentelemetry-proto-1.37.0\n  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.37.0\n    Uninstalling opentelemetry-api-1.37.0:\n      Successfully uninstalled opentelemetry-api-1.37.0\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.37.0\n    Uninstalling opentelemetry-sdk-1.37.0:\n      Successfully uninstalled opentelemetry-sdk-1.37.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nxmanager 0.7.1 requires sqlalchemy==1.2.19, but you have sqlalchemy 2.0.45 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed SQLAlchemy-2.0.45 backoff-2.2.1 bcrypt-5.0.0 bitsandbytes-0.49.1 chromadb-1.4.1 coloredlogs-15.0.1 colpali-engine-0.3.13 groq-0.37.1 httptools-0.7.1 humanfriendly-10.0 langchain-community-0.3.31 langchain-experimental-0.3.4 langchain-groq-0.3.8 langchain-huggingface-0.3.1 langgraph-1.0.1 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.15 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 ormsgpack-1.12.1 posthog-5.4.0 pybase64-1.4.3 pymupdf-1.26.7 pypika-0.50.0 pyzbar-0.1.9 rank_bm25-0.2.2 uvloop-0.22.1 watchfiles-1.1.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport torch\nimport fitz  # PyMuPDF\nimport numpy as np\nimport warnings\nimport chromadb\nfrom typing import List, TypedDict, Any, Dict\nfrom PIL import Image as PILImage\nfrom pyzbar.pyzbar import decode\nfrom tqdm.notebook import tqdm\n\n# LangChain / LangGraph\nfrom langchain_groq import ChatGroq\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import JsonOutputParser, StrOutputParser\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain.retrievers import EnsembleRetriever\nfrom langchain_huggingface import HuggingFaceEmbeddings \nfrom langgraph.graph import StateGraph, END\nfrom langchain_experimental.text_splitter import SemanticChunker\n\n# Vision Models\nfrom colpali_engine.models import ColPali, ColPaliProcessor\nfrom transformers import BitsAndBytesConfig\n\nwarnings.filterwarnings(\"ignore\")\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"✅ Hardware Accelerator: {DEVICE}\")\n\n# --- API KEY SETUP ---\n# Ensure your Groq API Key is set here or in Kaggle Secrets\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    os.environ[\"GROQ_API_KEY\"] = user_secrets.get_secret(\"GROQ_API_KEY\")\n    print(\"✅ GROQ_API_KEY loaded from Secrets.\")\nexcept:\n    # Manual Fallback if not using Kaggle Secrets\n    if \"GROQ_API_KEY\" not in os.environ:\n        os.environ[\"GROQ_API_KEY\"] = \"YOUR_GROQ_API_KEY_HERE\"\n        print(\"⚠️ Used manual API key placeholder. Replace if needed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:37:59.021886Z","iopub.execute_input":"2026-01-15T17:37:59.022513Z","iopub.status.idle":"2026-01-15T17:37:59.158114Z","shell.execute_reply.started":"2026-01-15T17:37:59.022487Z","shell.execute_reply":"2026-01-15T17:37:59.157559Z"}},"outputs":[{"name":"stdout","text":"✅ Hardware Accelerator: cuda\n✅ GROQ_API_KEY loaded from Secrets.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\nimport torch\nimport fitz  # PyMuPDF\nimport numpy as np\nimport warnings\nimport chromadb\nfrom typing import List, TypedDict, Any, Dict\nfrom PIL import Image as PILImage\nfrom pyzbar.pyzbar import decode\nfrom tqdm.notebook import tqdm\n\n# LangChain / LangGraph\nfrom langchain_groq import ChatGroq\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import JsonOutputParser, StrOutputParser\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain_huggingface import HuggingFaceEmbeddings \nfrom langgraph.graph import StateGraph, END\nfrom langchain_experimental.text_splitter import SemanticChunker\n\n# Vision Models\nfrom colpali_engine.models import ColPali, ColPaliProcessor\nfrom transformers import BitsAndBytesConfig\n\nwarnings.filterwarnings(\"ignore\")\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# --- 1. ENGINE CLASS (Fixes InvalidArgumentError) ---\nclass ByteMeEngine:\n    def __init__(self):\n        # A. Vision Model (ColPali)\n        print(\">> Loading ColPali (Vision Model)...\")\n        bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16)\n        self.colpali_model = ColPali.from_pretrained(\"vidore/colpali-v1.2\", quantization_config=bnb_config, torch_dtype=torch.float16, device_map=\"auto\")\n        self.colpali_processor = ColPaliProcessor.from_pretrained(\"vidore/colpali-v1.2\")\n        \n        # B. Text Embedder (MiniLM - 384 dim)\n        self.dense_embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device': DEVICE})\n        self.text_splitter = SemanticChunker(self.dense_embedder)\n\n        # C. ChromaDB: SEPARATE COLLECTIONS\n        self.db_path = \"/kaggle/working/chroma_db\"\n        self.client = chromadb.PersistentClient(path=self.db_path)\n        \n        # Collection 1: Text (384 dimensions)\n        self.text_collection = self.client.get_or_create_collection(\n            name=\"text_store\", \n            metadata={\"hnsw:space\": \"cosine\"}\n        )\n        \n        # Collection 2: Vision (ColPali dimensions)\n        self.vision_collection = self.client.get_or_create_collection(\n            name=\"vision_store\", \n            metadata={\"hnsw:space\": \"cosine\"}\n        )\n        \n        # D. Sparse Retriever\n        self.bm25_retriever = None\n\n    def process_pdf(self, pdf_path: str):\n        print(f\"🚀 Ingesting: {pdf_path}\")\n        doc = fitz.open(pdf_path)\n        \n        # Lists for Batch Processing\n        vis_ids, vis_vecs, vis_metas, vis_docs = [], [], [], []\n        txt_ids, txt_vecs, txt_metas, txt_docs = [], [], [], []\n        full_text_list = []\n\n        # 1. Vision Processing\n        for page_num, page in enumerate(tqdm(doc, desc=\"Vision Encoding\")):\n            # Image & QR\n            pix = page.get_pixmap(dpi=150)\n            img_np = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)\n            pil_img = PILImage.fromarray(img_np)\n            qr_data = [obj.data.decode('utf-8') for obj in decode(img_np)]\n            qr_text = f\" [QR: {qr_data}]\" if qr_data else \"\"\n            \n            # Embed Image (ColPali)\n            with torch.no_grad():\n                batch = self.colpali_processor.process_images([pil_img]).to(DEVICE)\n                emb = self.colpali_model(**batch)\n                # POOLING: Average patches to get single vector\n                pooled_emb = torch.mean(emb, dim=1).float().cpu().numpy()[0].tolist()\n\n            vis_ids.append(f\"vis_{page_num}\")\n            vis_vecs.append(pooled_emb)\n            # Store minimal text in vision doc to allow retrieval verification\n            content_preview = (page.get_text()[:200] + qr_text).replace(\"\\n\", \" \")\n            vis_metas.append({\"source\": pdf_path, \"page\": page_num+1, \"type\": \"vision\"})\n            vis_docs.append(content_preview)\n            full_text_list.append(page.get_text())\n\n        # 2. Text Processing (Semantic Chunking)\n        print(\">> Semantic Chunking & Text Embedding...\")\n        text_chunks = self.text_splitter.create_documents(full_text_list)\n        text_embeddings = self.dense_embedder.embed_documents([t.page_content for t in text_chunks])\n        \n        for i, chunk in enumerate(text_chunks):\n            txt_ids.append(f\"txt_{i}\")\n            txt_vecs.append(text_embeddings[i])\n            txt_metas.append({\"source\": pdf_path, \"type\": \"text\"})\n            txt_docs.append(chunk.page_content)\n\n        # 3. Upsert to Respective Collections\n        if vis_ids:\n            print(f\">> Indexing {len(vis_ids)} Vision Pages...\")\n            self.vision_collection.upsert(ids=vis_ids, embeddings=vis_vecs, metadatas=vis_metas, documents=vis_docs)\n            \n        if txt_ids:\n            print(f\">> Indexing {len(txt_ids)} Text Chunks...\")\n            self.text_collection.upsert(ids=txt_ids, embeddings=txt_vecs, metadatas=txt_metas, documents=txt_docs)\n\n        # 4. Build BM25\n        print(\">> Building BM25 Index...\")\n        self.bm25_retriever = BM25Retriever.from_texts(full_text_list)\n        self.bm25_retriever.k = 3\n        print(\"✅ Ingestion Complete.\")\n\n    def hybrid_search(self, query: str, k=5) -> List[str]:\n        \"\"\"Queries Text (Dense + Sparse) and Vision collections and merges results.\"\"\"\n        results = []\n        \n        # A. Text Dense Search\n        q_dense = self.dense_embedder.embed_query(query)\n        txt_res = self.text_collection.query(query_embeddings=[q_dense], n_results=k)\n        if txt_res['documents']: results.extend(txt_res['documents'][0])\n        \n        # B. Vision Dense Search (Using ColPali on Query)\n        with torch.no_grad():\n            # ColPali expects query as a list of strings\n            batch = self.colpali_processor.process_queries([query]).to(DEVICE)\n            emb = self.colpali_model(**batch)\n            q_vis = torch.mean(emb, dim=1).float().cpu().numpy()[0].tolist()\n            \n        vis_res = self.vision_collection.query(query_embeddings=[q_vis], n_results=k)\n        if vis_res['documents']: results.extend(vis_res['documents'][0])\n        \n        # C. BM25 Sparse Search\n        if self.bm25_retriever:\n            sparse_res = self.bm25_retriever.invoke(query)\n            results.extend([d.page_content for d in sparse_res])\n            \n        # Deduplicate\n        return list(set(results))\n\n# Initialize Engine\nengine = ByteMeEngine()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:21:08.832935Z","iopub.execute_input":"2026-01-15T17:21:08.833316Z","iopub.status.idle":"2026-01-15T17:22:56.152141Z","shell.execute_reply.started":"2026-01-15T17:21:08.833269Z","shell.execute_reply":"2026-01-15T17:22:56.151564Z"}},"outputs":[{"name":"stderr","text":"2026-01-15 17:21:28.611914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768497688.942839      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768497689.037332      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768497689.845998      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768497689.846036      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768497689.846039      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768497689.846041      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"name":"stdout","text":">> Loading ColPali (Vision Model)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/750 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96a6bba5aa4f46e0b630f6c50ee091d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"805f7fd1c82c4efba140e2c033c0c080"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf1a104e3aa341d5af3b2f6fc20dfac7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da65e1ae5c294f73be35dba64512d46a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5af6d27c3a1f4d2280169288aafec3a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/862M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92bc9cc1da2d4951aada7c951059ced7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccc38b7b18874ce1b45b9bd58363cdb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/78.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4002a4112edd4b6781ac7783471caa28"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/700 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea479b8763d244f1a9de8627eae31bab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"024ccc04ac92474d9cc2799f01b7e881"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8d4de0f694d4465994365910d268d5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/733 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47dc0e81a89344fa8c1b784d81988ba9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"131f7387e3da44ff8e095026c345cf3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23cf09157ffd4348bf5998de3e225bd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01b96297151c4c53a3eebb48639a1e30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b43c333ca40343f7be62a753aae8668e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7460931841c74b37892e8551b0ed661a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cb2f56c5d91409fb28fb68a77e5a37d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3705c64fe12147848078275aa4cd6dcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54f48a6f31a34c1abd8a95013c813879"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd741b9eacaa4c0fa10c304e137494e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"242ab7dec8bf420f880792d84374f37b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efc788359f56401cadab28caa91f010d"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# 1. Auto-Find PDF\npdf_path = None\nfor root, _, files in os.walk(\"/kaggle/input\"):\n    for f in files:\n        if f.endswith(\".pdf\"):\n            pdf_path = os.path.join(root, f)\n            break\n\nif pdf_path:\n    # 2. Ingest\n    engine.process_pdf(pdf_path)\nelse:\n    print(\"❌ No PDF found! Please upload a PDF to /kaggle/input.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:24:48.473633Z","iopub.execute_input":"2026-01-15T17:24:48.474479Z","iopub.status.idle":"2026-01-15T17:32:54.138051Z","shell.execute_reply.started":"2026-01-15T17:24:48.474451Z","shell.execute_reply":"2026-01-15T17:32:54.137001Z"}},"outputs":[{"name":"stdout","text":"🚀 Ingesting: /kaggle/input/hcl-data/Annual-Report-2024-25.pdf\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Vision Encoding:   0%|          | 0/423 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b2050689884432fae340c2ddc1cbb55"}},"metadata":{}},{"name":"stderr","text":"WARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=21 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=31 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=4 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=4 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=4 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=8 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=4 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=8 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=8 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=17 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=4 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=5 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=9 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=5 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=7 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=5 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=7 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=7 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=5 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=19 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=5 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=14 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=5 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=19 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=19 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=7 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=19 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=18 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=19 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=10 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=18 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=10 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=10 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=19 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=11 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=10 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=16 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=5 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=6 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=5 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=10 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=13 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=13 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=14 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=0 f=-1(101) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=23 f=-1(100) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=6 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=16 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=15 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=23 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=22 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=27 f=-1(000) part=0\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=31 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=28 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=28 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=2 f=-1(000) part=1\nWARNING: decoder/databar.c:1248: _zbar_decode_databar: Assertion \"seg->finder >= 0\" failed.\n\ti=3 f=-1(000) part=1\n","output_type":"stream"},{"name":"stdout","text":">> Semantic Chunking & Text Embedding...\n>> Indexing 423 Vision Pages...\n>> Indexing 910 Text Chunks...\n>> Building BM25 Index...\n✅ Ingestion Complete.\n\n❓ User: What is the consolidated revenue growth?\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/311421999.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What is the consolidated revenue growth?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n❓ User: {user_query}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mfinal_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"retries\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'app' is not defined"],"ename":"NameError","evalue":"name 'app' is not defined","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"# Memory-augmented LLM instances\nllm_router = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\nllm_gen = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0.3)  # Slightly higher temp for creativity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:00:25.402281Z","iopub.execute_input":"2026-01-15T18:00:25.402970Z","iopub.status.idle":"2026-01-15T18:00:25.594242Z","shell.execute_reply.started":"2026-01-15T18:00:25.402945Z","shell.execute_reply":"2026-01-15T18:00:25.593684Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import json\nimport ast\nfrom langgraph.graph import StateGraph, END\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\n# --- 1. ROBUST PARSING HELPER ---\ndef parse_json_safe(text_output):\n    \"\"\"\n    Safely parses LLM output that might use single quotes or markdown blocks.\n    \"\"\"\n    # Clean markdown\n    text = text_output.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n    \n    try:\n        # Try standard JSON\n        return json.loads(text)\n    except json.JSONDecodeError:\n        try:\n            # Try Python literal eval (handles single quotes)\n            return ast.literal_eval(text)\n        except:\n            # Fallback: simple string search\n            if \"yes\" in text.lower(): return {\"score\": \"yes\"}\n            return {\"score\": \"no\"}\n\n# --- 2. IMPROVED PROMPTS & CHAINS ---\nrag_chain = (\n    PromptTemplate(template=\"Context: {context} \\n Q: {question} \\n Answer:\", input_variables=[\"context\", \"question\"]) \n    | llm_gen \n    | StrOutputParser()\n)\n# A. Rewriter\nrewrite_prompt = PromptTemplate(\n    template=\"\"\"You are a search query optimizer. \n    Rewrite the user's question to be short, specific, and keyword-rich for a vector database.\n    Do NOT output a list. Output ONLY the rewritten query string.\n    \n    Original: {question}\n    New Query:\"\"\",\n    input_variables=[\"question\"]\n)\n# Use StrOutputParser (Text only)\nrewriter_chain = rewrite_prompt | llm_router | StrOutputParser()\n\n# B. Grader\ngrade_prompt = PromptTemplate(\n    template=\"\"\"You are a grader assessing relevance. \n    Does the document contain ANY information related to the user's question?\n    \n    Document: {document}\n    Question: {question}\n    \n    Return strictly valid JSON: {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\"\"\",\n    input_variables=[\"question\", \"document\"]\n)\n# Use StrOutputParser + Manual Safe Parse\ngrader_chain = grade_prompt | llm_router | StrOutputParser()\n\n# C. Grounding\ngrounding_prompt = PromptTemplate(\n    template=\"\"\"Context: {context} \n    Answer: {generation} \n    \n    Is the answer fully supported by the context? \n    Return strictly valid JSON: {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\"\"\",\n    input_variables=[\"context\", \"generation\"]\n)\n# Use StrOutputParser + Manual Safe Parse\ngrounding_chain = grounding_prompt | llm_router | StrOutputParser()\n\n# --- 3. GRAPH DEFINITION ---\n\nclass AgentState(TypedDict):\n    question: str\n    documents: List[str]\n    generation: str\n    is_grounded: bool\n    retries: int \n\ndef retrieve_node(state):\n    print(f\"🔍 Hybrid Retrieval for: '{state['question']}'\")\n    docs = engine.hybrid_search(state[\"question\"])\n    return {\"documents\": docs, \"retries\": state.get(\"retries\", 0)}\n\ndef grade_node(state):\n    print(\"📝 Grading Retrieval Quality...\")\n    relevant = []\n    \n    if not state[\"documents\"]: \n        return {\"documents\": [], \"retries\": state[\"retries\"] + 1}\n        \n    for doc in state[\"documents\"]:\n        try:\n            # RAW TEXT output from LLM\n            raw_res = grader_chain.invoke({\"question\": state[\"question\"], \"document\": doc})\n            # SAFE PARSE\n            parsed_res = parse_json_safe(raw_res)\n            \n            if parsed_res.get(\"score\") == \"yes\":\n                relevant.append(doc)\n        except: continue\n    \n    # Increment retries if grading failed\n    new_retries = state[\"retries\"] + 1 if not relevant else state[\"retries\"]\n    return {\"documents\": relevant, \"retries\": new_retries}\n\ndef rewrite_node(state):\n    print(\"🔄 Retrieval Poor. Rewriting Query...\")\n    new_q = rewriter_chain.invoke({\"question\": state[\"question\"]})\n    new_q = new_q.strip().replace('\"', '')\n    print(f\"   -> New Query: '{new_q}'\")\n    return {\"question\": new_q}\n\ndef generate_node(state):\n    print(\"💡 Generating Answer...\")\n    gen = rag_chain.invoke({\"context\": state[\"documents\"], \"question\": state[\"question\"]})\n    return {\"generation\": gen}\n\ndef graceful_fail_node(state):\n    print(\"❌ Max Retries Reached. Returning fallback.\")\n    return {\"generation\": \"I'm sorry, I tried several times but couldn't find relevant information in the provided document to answer your question. Please try rephrasing.\"}\n\ndef reflection_node(state):\n    print(\"🛡️ Verifying Grounding...\")\n    if \"I'm sorry\" in state[\"generation\"]:\n        return {\"is_grounded\": False}\n        \n    raw_res = grounding_chain.invoke({\"context\": state[\"documents\"], \"generation\": state[\"generation\"]})\n    parsed_res = parse_json_safe(raw_res)\n    \n    if parsed_res.get(\"score\") == \"no\":\n        return {\"is_grounded\": False, \"generation\": \"I found some documents, but the answer I generated couldn't be fully verified against them.\"}\n    return {\"is_grounded\": True}\n\n# Build Graph\nworkflow = StateGraph(AgentState)\nworkflow.add_node(\"retrieve\", retrieve_node)\nworkflow.add_node(\"grade\", grade_node)\nworkflow.add_node(\"rewrite\", rewrite_node)\nworkflow.add_node(\"generate\", generate_node)\nworkflow.add_node(\"reflect\", reflection_node)\nworkflow.add_node(\"fail\", graceful_fail_node)\n\nworkflow.set_entry_point(\"retrieve\")\nworkflow.add_edge(\"retrieve\", \"grade\")\n\ndef check_relevance(state):\n    if state[\"documents\"]: return \"generate\"\n    if state[\"retries\"] > 2: return \"fail\"\n    return \"rewrite\"\n\nworkflow.add_conditional_edges(\"grade\", check_relevance)\nworkflow.add_edge(\"rewrite\", \"retrieve\")\nworkflow.add_edge(\"generate\", \"reflect\")\nworkflow.add_edge(\"reflect\", END)\nworkflow.add_edge(\"fail\", END)\n\napp = workflow.compile()\nprint(\"✅ Robust Agent Graph Compiled.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:39:42.275602Z","iopub.execute_input":"2026-01-15T17:39:42.276146Z","iopub.status.idle":"2026-01-15T17:39:42.297783Z","shell.execute_reply.started":"2026-01-15T17:39:42.276119Z","shell.execute_reply":"2026-01-15T17:39:42.296941Z"}},"outputs":[{"name":"stdout","text":"✅ Robust Agent Graph Compiled.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"if 'engine' in globals():\n    q = \"What is the consolidated revenue growth?\"\n    print(f\"\\n❓ User: {q}\")\n    \n    # Invoke the app\n    res = app.invoke({\"question\": q, \"retries\": 0})\n    \n    print(\"\\n\" + \"=\"*40)\n    print(f\"✅ Final Answer:\\n{res.get('generation', 'No answer generated.')}\")\n    print(\"=\"*40)\nelse:\n    print(\"❌ Engine not found. Please run the Ingestion cell first.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:39:45.706087Z","iopub.execute_input":"2026-01-15T17:39:45.706416Z","iopub.status.idle":"2026-01-15T17:39:48.441126Z","shell.execute_reply.started":"2026-01-15T17:39:45.706392Z","shell.execute_reply":"2026-01-15T17:39:48.440564Z"}},"outputs":[{"name":"stdout","text":"\n❓ User: What is the consolidated revenue growth?\n🔍 Hybrid Retrieval for: 'What is the consolidated revenue growth?'\n📝 Grading Retrieval Quality...\n💡 Generating Answer...\n🛡️ Verifying Grounding...\n\n========================================\n✅ Final Answer:\nThe consolidated revenue growth is 6.5%. This is based on the increase in revenue from operations from ₹109,913 crores in the year ended 31 March 2024 to ₹117,055 crores in the year ended 31 March 2025.\n========================================\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# List of test questions targeting different capabilities (Vision, Text, Reasoning, Negative)\ntest_questions = [\n    \"What is the trend of attrition rate over the last 3 years?\",\n    \"How is revenue distributed across different geographies?\",\n    \"What is the recommended final dividend per share for FY25?\",\n    \"Summarize the company's progress on its sustainability or ESG goals.\",\n    \"What is the projected revenue for FY 2030?\"  # Negative test\n]\n\nprint(\"🚀 Starting Evaluation Run...\\n\")\n\nif 'app' in globals() and 'engine' in globals():\n    for i, q in enumerate(test_questions, 1):\n        print(f\"\\n❓ Question {i}: {q}\")\n        \n        # Invoke the Agent\n        try:\n            res = app.invoke({\"question\": q, \"retries\": 0})\n            answer = res.get(\"generation\", \"No answer generated.\")\n            \n            print(\"-\" * 20)\n            print(f\"✅ Agent Answer:\\n{answer}\")\n            print(\"-\" * 40)\n            \n        except Exception as e:\n            print(f\"❌ Error: {e}\")\nelse:\n    print(\"❌ Agent app or Engine not found. Please ensure previous cells were run successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:40:01.066118Z","iopub.execute_input":"2026-01-15T17:40:01.066694Z","iopub.status.idle":"2026-01-15T17:47:35.728661Z","shell.execute_reply.started":"2026-01-15T17:40:01.066666Z","shell.execute_reply":"2026-01-15T17:47:35.728006Z"}},"outputs":[{"name":"stdout","text":"🚀 Starting Evaluation Run...\n\n\n❓ Question 1: What is the trend of attrition rate over the last 3 years?\n🔍 Hybrid Retrieval for: 'What is the trend of attrition rate over the last 3 years?'\n📝 Grading Retrieval Quality...\n💡 Generating Answer...\n🛡️ Verifying Grounding...\n--------------------\n✅ Agent Answer:\nThe provided context is insufficient to determine the trend of the attrition rate over the last 3 years. The given information only includes a date (31 March 2024) and a percentage (7.50%), but it does not provide any data on attrition rates for the previous years. To analyze the trend, we would need more information, such as the attrition rates for 2022 and 2023.\n----------------------------------------\n\n❓ Question 2: How is revenue distributed across different geographies?\n🔍 Hybrid Retrieval for: 'How is revenue distributed across different geographies?'\n📝 Grading Retrieval Quality...\n💡 Generating Answer...\n🛡️ Verifying Grounding...\n--------------------\n✅ Agent Answer:\nThe revenue distribution across different geographies is as follows:\n\n- United States of America (USA): 58.1% (₹67,987 crores)\n- Europe: 26.7% (₹31,240 crores)\n- India: 3.1% (₹3,667 crores)\n- Rest of the world: 12.1% (₹14,161 crores)\n\nThis distribution is based on the revenue for the year ended 31 March 2025. The revenue has seen a growth of 6.5% compared to the previous year, with notable increases in the USA (7.2%) and Europe (6.7%).\n----------------------------------------\n\n❓ Question 3: What is the recommended final dividend per share for FY25?\n🔍 Hybrid Retrieval for: 'What is the recommended final dividend per share for FY25?'\n📝 Grading Retrieval Quality...\n💡 Generating Answer...\n🛡️ Verifying Grounding...\n--------------------\n✅ Agent Answer:\nThe text does not provide the recommended final dividend per share for FY25. It only explains the accounting policy for dividend recognition, stating that the final dividend proposed by the Board of Directors is recognized upon approval by the shareholders. To determine the recommended final dividend per share, you would need to refer to a different section of the annual report, such as the Director's Report or the Financial Highlights section, which is not provided in the given context.\n----------------------------------------\n\n❓ Question 4: Summarize the company's progress on its sustainability or ESG goals.\n🔍 Hybrid Retrieval for: 'Summarize the company's progress on its sustainability or ESG goals.'\n📝 Grading Retrieval Quality...\n💡 Generating Answer...\n🛡️ Verifying Grounding...\n--------------------\n✅ Agent Answer:\nHCLTech has made significant progress on its sustainability and ESG goals. The company has established a robust ESG governance framework, which includes a dedicated ESG and DEI Committee that meets quarterly to review and assess ESG risks and opportunities. The company has set specific commitments, goals, and targets across three pillars: Planet, People, and Governance.\n\nUnder the Planet pillar, HCLTech aims to achieve net zero by 2040, reduce absolute Scope 1 and 2 emissions by 50% by 2030, and transition 80% of its electricity usage to renewable energy by 2030. The company has also set targets to reduce absolute Scope 3 emissions by 42% by 2030 and achieve zero waste to landfill at all owned facilities by 2025.\n\nUnder the People pillar, HCLTech aims to improve the sustainability knowledge and skills of its employees, improve gender diversity in the personnel with 40% women by 2030, and increase gender representation in senior leadership levels to 30% by 2030.\n\nThe company has also integrated ESG into its procurement process and has conducted risk evaluations of its supply chain based on ESG guidelines. HCLTech has incorporated ESG criteria into its vendor selection process and has established a Vendor Risk Management program to ensure that its suppliers adhere to ESG standards.\n\nOverall, HCLTech has made significant progress on its ESG goals and is committed to creating a resilient and responsible supply chain that supports long-term business growth and contributes to global sustainability goals. The company's ESG and DEI Committee provides oversight and guidance on ESG matters, and the company provides regular updates on its ESG performance to stakeholders.\n----------------------------------------\n\n❓ Question 5: What is the projected revenue for FY 2030?\n🔍 Hybrid Retrieval for: 'What is the projected revenue for FY 2030?'\n📝 Grading Retrieval Quality...\n🔄 Retrieval Poor. Rewriting Query...\n   -> New Query: 'Projected revenue FY 2030 vector database query'\n🔍 Hybrid Retrieval for: 'Projected revenue FY 2030 vector database query'\n📝 Grading Retrieval Quality...\n🔄 Retrieval Poor. Rewriting Query...\n   -> New Query: 'Projected revenue FY 2030 vector database query optimization'\n🔍 Hybrid Retrieval for: 'Projected revenue FY 2030 vector database query optimization'\n📝 Grading Retrieval Quality...\n❌ Max Retries Reached. Returning fallback.\n--------------------\n✅ Agent Answer:\nI'm sorry, I tried several times but couldn't find relevant information in the provided document to answer your question. Please try rephrasing.\n----------------------------------------\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import shutil\n\nfolder_path = \"/kaggle/working/chroma_db\"   # or any folder\nzip_path = \"/kaggle/working/chroma_db.zip\"\n\nshutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', folder_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:53:22.408960Z","iopub.execute_input":"2026-01-15T17:53:22.409292Z","iopub.status.idle":"2026-01-15T17:53:23.186957Z","shell.execute_reply.started":"2026-01-15T17:53:22.409265Z","shell.execute_reply":"2026-01-15T17:53:23.186359Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/chroma_db.zip'"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"from datetime import datetime\nfrom collections import deque\nimport hashlib\n\nclass MemoryManager:\n    \"\"\"\n    Professional Memory Management System for Agentic RAG\n    Implements both short-term (working memory) and long-term (persistent) memory\n    \"\"\"\n    \n    def __init__(self, chromadb_client, embedder, max_short_term=10):\n        \"\"\"\n        Args:\n            chromadb_client: ChromaDB client instance\n            embedder: HuggingFace embeddings model\n            max_short_term: Maximum number of recent exchanges to keep in short-term memory\n        \"\"\"\n        self.embedder = embedder\n        self.max_short_term = max_short_term\n        \n        # SHORT-TERM MEMORY: In-memory conversation buffer (FIFO queue)\n        self.conversation_buffer = deque(maxlen=max_short_term)\n        \n        # LONG-TERM MEMORY: Persistent ChromaDB collections\n        self.memory_collection = chromadb_client.get_or_create_collection(\n            name=\"long_term_memory\",\n            metadata={\"hnsw:space\": \"cosine\"}\n        )\n        \n        self.facts_collection = chromadb_client.get_or_create_collection(\n            name=\"extracted_facts\",\n            metadata={\"hnsw:space\": \"cosine\"}\n        )\n        \n        print(\"✅ Memory Manager Initialized\")\n        print(f\"   - Short-term capacity: {max_short_term} exchanges\")\n        print(f\"   - Long-term storage: ChromaDB (persistent)\")\n    \n    def add_exchange(self, question: str, answer: str, metadata: dict = None):\n        \"\"\"\n        Add a Q&A exchange to SHORT-TERM memory\n        \"\"\"\n        exchange = {\n            \"question\": question,\n            \"answer\": answer,\n            \"timestamp\": datetime.now().isoformat(),\n            \"metadata\": metadata or {}\n        }\n        self.conversation_buffer.append(exchange)\n        return exchange\n    \n    def get_recent_history(self, n: int = None) -> List[Dict]:\n        \"\"\"\n        Retrieve recent conversation history from SHORT-TERM memory\n        \"\"\"\n        n = n or self.max_short_term\n        return list(self.conversation_buffer)[-n:]\n    \n    def format_history_for_prompt(self, n: int = 3) -> str:\n        \"\"\"\n        Format recent history as a string for LLM context\n        \"\"\"\n        history = self.get_recent_history(n)\n        if not history:\n            return \"No previous conversation.\"\n        \n        formatted = []\n        for i, exch in enumerate(history, 1):\n            formatted.append(f\"[{i}] Q: {exch['question']}\\n    A: {exch['answer'][:150]}...\")\n        \n        return \"\\n\".join(formatted)\n    \n    def store_to_long_term(self, question: str, answer: str, importance_score: float = 0.5):\n        \"\"\"\n        Persist important exchanges to LONG-TERM memory (ChromaDB)\n        Args:\n            importance_score: 0-1, higher = more important (for future filtering)\n        \"\"\"\n        # Create unique ID based on content hash\n        content = f\"{question}|{answer}\"\n        mem_id = hashlib.md5(content.encode()).hexdigest()\n        \n        # Embed the Q&A pair\n        embedding = self.embedder.embed_query(f\"Question: {question} Answer: {answer}\")\n        \n        # Store with metadata\n        self.memory_collection.upsert(\n            ids=[mem_id],\n            embeddings=[embedding],\n            documents=[content],\n            metadatas=[{\n                \"question\": question,\n                \"answer\": answer[:500],  # Truncate long answers\n                \"timestamp\": datetime.now().isoformat(),\n                \"importance\": importance_score\n            }]\n        )\n        return mem_id\n    \n    def retrieve_relevant_memories(self, query: str, n_results: int = 3) -> List[Dict]:\n        \"\"\"\n        Semantic search over LONG-TERM memory for relevant past conversations\n        \"\"\"\n        query_embedding = self.embedder.embed_query(query)\n        results = self.memory_collection.query(\n            query_embeddings=[query_embedding],\n            n_results=n_results\n        )\n        \n        memories = []\n        if results['metadatas'] and results['metadatas'][0]:\n            for meta in results['metadatas'][0]:\n                memories.append({\n                    \"question\": meta.get(\"question\", \"\"),\n                    \"answer\": meta.get(\"answer\", \"\"),\n                    \"timestamp\": meta.get(\"timestamp\", \"\")\n                })\n        \n        return memories\n    \n    def extract_and_store_facts(self, text: str, source: str = \"conversation\"):\n        \"\"\"\n        Extract key facts from text and store in dedicated facts collection\n        (Placeholder for future LLM-based fact extraction)\n        \"\"\"\n        # Simple implementation: store as-is with embedding\n        fact_id = hashlib.md5(f\"{text}{datetime.now()}\".encode()).hexdigest()\n        embedding = self.embedder.embed_query(text)\n        \n        self.facts_collection.upsert(\n            ids=[fact_id],\n            embeddings=[embedding],\n            documents=[text],\n            metadatas=[{\n                \"source\": source,\n                \"timestamp\": datetime.now().isoformat()\n            }]\n        )\n    \n    def consolidate_memory(self, llm_summarizer=None):\n        \"\"\"\n        Consolidate old short-term memories into long-term storage\n        Called periodically or when buffer is full\n        \"\"\"\n        if len(self.conversation_buffer) >= self.max_short_term - 1:\n            # Store oldest exchanges to long-term\n            for exch in list(self.conversation_buffer)[:3]:  # Store oldest 3\n                self.store_to_long_term(\n                    exch['question'], \n                    exch['answer'], \n                    importance_score=0.6  # Default importance\n                )\n            print(\"🗄️ Consolidated 3 exchanges to long-term memory\")\n    \n    def clear_short_term(self):\n        \"\"\"Reset short-term memory (new session)\"\"\"\n        self.conversation_buffer.clear()\n        print(\"🧹 Short-term memory cleared\")\n\nprint(\"✅ MemoryManager class defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:00:03.993598Z","iopub.execute_input":"2026-01-15T18:00:03.994124Z","iopub.status.idle":"2026-01-15T18:00:04.010099Z","shell.execute_reply.started":"2026-01-15T18:00:03.994093Z","shell.execute_reply":"2026-01-15T18:00:04.009331Z"}},"outputs":[{"name":"stdout","text":"✅ MemoryManager class defined\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Initialize Memory Manager with the engine's ChromaDB client\nmemory_manager = MemoryManager(\n    chromadb_client=engine.client,\n    embedder=engine.dense_embedder,\n    max_short_term=10  # Keep last 10 Q&A pairs in short-term memory\n)\n\nprint(\"🧠 Memory system ready for use\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:00:09.102243Z","iopub.execute_input":"2026-01-15T18:00:09.102938Z","iopub.status.idle":"2026-01-15T18:00:09.131297Z","shell.execute_reply.started":"2026-01-15T18:00:09.102911Z","shell.execute_reply":"2026-01-15T18:00:09.130629Z"}},"outputs":[{"name":"stdout","text":"✅ Memory Manager Initialized\n   - Short-term capacity: 10 exchanges\n   - Long-term storage: ChromaDB (persistent)\n🧠 Memory system ready for use\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import json\nimport ast\nfrom langgraph.graph import StateGraph, END\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\n# --- 1. ROBUST PARSING HELPER ---\ndef parse_json_safe(text_output):\n    \"\"\"\n    Safely parses LLM output that might use single quotes or markdown blocks.\n    \"\"\"\n    # Clean markdown\n    text = text_output.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n    \n    try:\n        # Try standard JSON\n        return json.loads(text)\n    except json.JSONDecodeError:\n        try:\n            # Try Python literal eval (handles single quotes)\n            return ast.literal_eval(text)\n        except:\n            # Fallback: simple string search\n            if \"yes\" in text.lower(): return {\"score\": \"yes\"}\n            return {\"score\": \"no\"}\n\n# --- 2. MEMORY-AUGMENTED PROMPTS & CHAINS ---\n\n# A. Memory Retrieval Prompt (NEW)\nmemory_retrieval_prompt = PromptTemplate(\n    template=\"\"\"Based on the current question, determine if we need context from previous conversations.\n    \n    Current Question: {question}\n    \n    Should we retrieve conversation history? Return JSON: {{\"retrieve\": \"yes\"}} or {{\"retrieve\": \"no\"}}\"\"\",\n    input_variables=[\"question\"]\n)\nmemory_decision_chain = memory_retrieval_prompt | llm_router | StrOutputParser()\n\n# B. RAG Chain with Memory Context (UPDATED)\nrag_with_memory_prompt = PromptTemplate(\n    template=\"\"\"You are a helpful assistant with access to document context and conversation history.\n    \n    📚 DOCUMENT CONTEXT:\n    {context}\n    \n    🧠 CONVERSATION HISTORY:\n    {memory_context}\n    \n    🧠 RELEVANT PAST CONVERSATIONS:\n    {long_term_memory}\n    \n    ❓ CURRENT QUESTION: {question}\n    \n    Instructions:\n    - Use the document context as your primary source\n    - Reference conversation history to maintain context continuity\n    - If the question refers to previous answers, use the memory\n    - Be concise and accurate\n    \n    Answer:\"\"\",\n    input_variables=[\"context\", \"memory_context\", \"long_term_memory\", \"question\"]\n)\nrag_chain = rag_with_memory_prompt | llm_gen | StrOutputParser()\n\n# C. Rewriter (Same)\nrewrite_prompt = PromptTemplate(\n    template=\"\"\"You are a search query optimizer. \n    Rewrite the user's question to be short, specific, and keyword-rich for a vector database.\n    Do NOT output a list. Output ONLY the rewritten query string.\n    \n    Original: {question}\n    New Query:\"\"\",\n    input_variables=[\"question\"]\n)\nrewriter_chain = rewrite_prompt | llm_router | StrOutputParser()\n\n# D. Grader (Same)\ngrade_prompt = PromptTemplate(\n    template=\"\"\"You are a grader assessing relevance. \n    Does the document contain ANY information related to the user's question?\n    \n    Document: {document}\n    Question: {question}\n    \n    Return strictly valid JSON: {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\"\"\",\n    input_variables=[\"question\", \"document\"]\n)\ngrader_chain = grade_prompt | llm_router | StrOutputParser()\n\n# E. Grounding (Same)\ngrounding_prompt = PromptTemplate(\n    template=\"\"\"Context: {context} \n    Answer: {generation} \n    \n    Is the answer fully supported by the context? \n    Return strictly valid JSON: {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\"\"\",\n    input_variables=[\"context\", \"generation\"]\n)\ngrounding_chain = grounding_prompt | llm_router | StrOutputParser()\n\n# --- 3. MEMORY-AUGMENTED GRAPH DEFINITION ---\n\nclass AgentState(TypedDict):\n    question: str\n    original_question: str  # NEW: Keep original for memory storage\n    documents: List[str]\n    generation: str\n    is_grounded: bool\n    retries: int\n    memory_context: str  # NEW: Short-term memory\n    long_term_memory: str  # NEW: Retrieved long-term memories\n    should_store_memory: bool  # NEW: Flag for memory storage\n\n# --- GRAPH NODES ---\n\ndef memory_retrieval_node(state):\n    \"\"\"NEW: Retrieve relevant memories before processing\"\"\"\n    print(\"🧠 Retrieving Relevant Memories...\")\n    \n    # Get short-term memory (recent conversation)\n    recent_history = memory_manager.format_history_for_prompt(n=3)\n    \n    # Get long-term memory (semantic search over past conversations)\n    long_term = memory_manager.retrieve_relevant_memories(state[\"question\"], n_results=2)\n    long_term_formatted = \"\\n\".join([\n        f\"Past Q: {m['question']}\\nPast A: {m['answer'][:200]}...\" \n        for m in long_term\n    ]) if long_term else \"No relevant past conversations found.\"\n    \n    return {\n        \"memory_context\": recent_history,\n        \"long_term_memory\": long_term_formatted,\n        \"original_question\": state.get(\"original_question\") or state[\"question\"]\n    }\n\ndef retrieve_node(state):\n    print(f\"🔍 Hybrid Retrieval for: '{state['question']}'\")\n    docs = engine.hybrid_search(state[\"question\"])\n    return {\"documents\": docs, \"retries\": state.get(\"retries\", 0)}\n\ndef grade_node(state):\n    print(\"📝 Grading Retrieval Quality...\")\n    relevant = []\n    \n    if not state[\"documents\"]: \n        return {\"documents\": [], \"retries\": state[\"retries\"] + 1}\n        \n    for doc in state[\"documents\"]:\n        try:\n            raw_res = grader_chain.invoke({\"question\": state[\"question\"], \"document\": doc})\n            parsed_res = parse_json_safe(raw_res)\n            \n            if parsed_res.get(\"score\") == \"yes\":\n                relevant.append(doc)\n        except: continue\n    \n    new_retries = state[\"retries\"] + 1 if not relevant else state[\"retries\"]\n    return {\"documents\": relevant, \"retries\": new_retries}\n\ndef rewrite_node(state):\n    print(\"🔄 Retrieval Poor. Rewriting Query...\")\n    new_q = rewriter_chain.invoke({\"question\": state[\"question\"]})\n    new_q = new_q.strip().replace('\"', '')\n    print(f\"   -> New Query: '{new_q}'\")\n    return {\"question\": new_q}\n\ndef generate_node(state):\n    print(\"💡 Generating Answer with Memory Context...\")\n    gen = rag_chain.invoke({\n        \"context\": state[\"documents\"], \n        \"question\": state[\"question\"],\n        \"memory_context\": state.get(\"memory_context\", \"\"),\n        \"long_term_memory\": state.get(\"long_term_memory\", \"\")\n    })\n    return {\"generation\": gen, \"should_store_memory\": True}\n\ndef graceful_fail_node(state):\n    print(\"❌ Max Retries Reached. Returning fallback.\")\n    return {\n        \"generation\": \"I'm sorry, I tried several times but couldn't find relevant information in the provided document to answer your question. Please try rephrasing.\",\n        \"should_store_memory\": False\n    }\n\ndef reflection_node(state):\n    print(\"🛡️ Verifying Grounding...\")\n    if \"I'm sorry\" in state[\"generation\"]:\n        return {\"is_grounded\": False}\n        \n    raw_res = grounding_chain.invoke({\"context\": state[\"documents\"], \"generation\": state[\"generation\"]})\n    parsed_res = parse_json_safe(raw_res)\n    \n    if parsed_res.get(\"score\") == \"no\":\n        return {\n            \"is_grounded\": False, \n            \"generation\": \"I found some documents, but the answer I generated couldn't be fully verified against them.\",\n            \"should_store_memory\": False\n        }\n    return {\"is_grounded\": True}\n\ndef memory_storage_node(state):\n    \"\"\"NEW: Store successful Q&A to memory\"\"\"\n    print(\"💾 Storing to Memory...\")\n    \n    if state.get(\"should_store_memory\") and state.get(\"is_grounded\"):\n        # Add to short-term memory\n        memory_manager.add_exchange(\n            question=state[\"original_question\"],\n            answer=state[\"generation\"],\n            metadata={\"grounded\": True}\n        )\n        \n        # Conditionally store to long-term (important conversations)\n        # You can add logic here to determine importance\n        importance = 0.7 if len(state[\"generation\"]) > 100 else 0.5\n        memory_manager.store_to_long_term(\n            question=state[\"original_question\"],\n            answer=state[\"generation\"],\n            importance_score=importance\n        )\n        \n        # Consolidate if buffer is full\n        memory_manager.consolidate_memory()\n        print(\"   ✅ Memory stored successfully\")\n    \n    return {}\n\n# --- BUILD GRAPH ---\nworkflow = StateGraph(AgentState)\n\n# Add all nodes\nworkflow.add_node(\"memory_retrieval\", memory_retrieval_node)  # NEW\nworkflow.add_node(\"retrieve\", retrieve_node)\nworkflow.add_node(\"grade\", grade_node)\nworkflow.add_node(\"rewrite\", rewrite_node)\nworkflow.add_node(\"generate\", generate_node)\nworkflow.add_node(\"reflect\", reflection_node)\nworkflow.add_node(\"memory_storage\", memory_storage_node)  # NEW\nworkflow.add_node(\"fail\", graceful_fail_node)\n\n# Set entry point - START WITH MEMORY RETRIEVAL\nworkflow.set_entry_point(\"memory_retrieval\")\nworkflow.add_edge(\"memory_retrieval\", \"retrieve\")\nworkflow.add_edge(\"retrieve\", \"grade\")\n\ndef check_relevance(state):\n    if state[\"documents\"]: return \"generate\"\n    if state[\"retries\"] > 2: return \"fail\"\n    return \"rewrite\"\n\nworkflow.add_conditional_edges(\"grade\", check_relevance)\nworkflow.add_edge(\"rewrite\", \"retrieve\")\nworkflow.add_edge(\"generate\", \"reflect\")\n\n# After reflection, store memory before ending\ndef check_reflection(state):\n    return \"memory_storage\"\n\nworkflow.add_edge(\"reflect\", \"memory_storage\")\nworkflow.add_edge(\"memory_storage\", END)\nworkflow.add_edge(\"fail\", END)\n\napp = workflow.compile()\nprint(\"✅ Memory-Augmented Agent Graph Compiled\")\nprint(\"   🧠 Short-term: Conversation buffer (in-memory)\")\nprint(\"   🗄️ Long-term: ChromaDB persistent storage\")\nprint(\"   ♻️ Auto-consolidation enabled\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:00:37.702146Z","iopub.execute_input":"2026-01-15T18:00:37.702855Z","iopub.status.idle":"2026-01-15T18:00:37.731531Z","shell.execute_reply.started":"2026-01-15T18:00:37.702831Z","shell.execute_reply":"2026-01-15T18:00:37.730772Z"}},"outputs":[{"name":"stdout","text":"✅ Memory-Augmented Agent Graph Compiled\n   🧠 Short-term: Conversation buffer (in-memory)\n   🗄️ Long-term: ChromaDB persistent storage\n   ♻️ Auto-consolidation enabled\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"if 'engine' in globals() and 'memory_manager' in globals():\n    q = \"What is the consolidated revenue growth?\"\n    print(f\"\\n❓ User: {q}\")\n    \n    # Invoke the memory-augmented app\n    res = app.invoke({\n        \"question\": q, \n        \"retries\": 0,\n        \"memory_context\": \"\",\n        \"long_term_memory\": \"\",\n        \"should_store_memory\": False\n    })\n    \n    print(\"\\n\" + \"=\"*40)\n    print(f\"✅ Final Answer:\\n{res.get('generation', 'No answer generated.')}\")\n    print(\"=\"*40)\n    \n    # Show memory status\n    print(f\"\\n🧠 Short-term memory: {len(memory_manager.conversation_buffer)} exchanges\")\nelse:\n    print(\"❌ Engine or Memory Manager not found. Please run previous cells first.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:02:32.509531Z","iopub.execute_input":"2026-01-15T18:02:32.510132Z","iopub.status.idle":"2026-01-15T18:02:36.072389Z","shell.execute_reply.started":"2026-01-15T18:02:32.510106Z","shell.execute_reply":"2026-01-15T18:02:36.071673Z"}},"outputs":[{"name":"stdout","text":"\n❓ User: What is the consolidated revenue growth?\n🧠 Retrieving Relevant Memories...\n🔍 Hybrid Retrieval for: 'What is the consolidated revenue growth?'\n📝 Grading Retrieval Quality...\n💡 Generating Answer with Memory Context...\n🛡️ Verifying Grounding...\n💾 Storing to Memory...\n   ✅ Memory stored successfully\n\n========================================\n✅ Final Answer:\nThe consolidated revenue growth is 6.5%, with revenue from operations increasing to ₹117,055 crores in the year ended 31 March 2025 from ₹109,913 crores in the year ended 31 March 2024.\n========================================\n\n🧠 Short-term memory: 1 exchanges\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# 🔧 MEMORY MANAGEMENT UTILITIES\n\ndef show_memory_stats():\n    \"\"\"Display comprehensive memory statistics\"\"\"\n    print(\"📊 MEMORY SYSTEM STATISTICS\")\n    print(\"=\"*50)\n    \n    # Short-term\n    print(f\"\\n🧠 SHORT-TERM MEMORY:\")\n    print(f\"   - Buffer size: {len(memory_manager.conversation_buffer)}/{memory_manager.max_short_term}\")\n    print(f\"   - Capacity: {(len(memory_manager.conversation_buffer)/memory_manager.max_short_term)*100:.1f}%\")\n    \n    # Long-term\n    long_term_count = memory_manager.memory_collection.count()\n    facts_count = memory_manager.facts_collection.count()\n    \n    print(f\"\\n🗄️ LONG-TERM MEMORY:\")\n    print(f\"   - Stored conversations: {long_term_count}\")\n    print(f\"   - Extracted facts: {facts_count}\")\n    print(f\"   - Total persistent records: {long_term_count + facts_count}\")\n\ndef search_memory(query: str, n=3):\n    \"\"\"Search through long-term memory\"\"\"\n    print(f\"\\n🔍 Searching memory for: '{query}'\")\n    memories = memory_manager.retrieve_relevant_memories(query, n_results=n)\n    \n    if memories:\n        print(f\"\\n✅ Found {len(memories)} relevant memories:\\n\")\n        for i, mem in enumerate(memories, 1):\n            print(f\"[{i}] Q: {mem['question']}\")\n            print(f\"    A: {mem['answer'][:150]}...\")\n            print(f\"    Time: {mem['timestamp']}\")\n            print()\n    else:\n        print(\"❌ No relevant memories found\")\n\ndef clear_all_memory():\n    \"\"\"Reset all memory (use with caution!)\"\"\"\n    confirm = input(\"⚠️ This will clear ALL memory. Type 'YES' to confirm: \")\n    if confirm == \"YES\":\n        memory_manager.clear_short_term()\n        # Note: ChromaDB collections persist - would need manual deletion\n        print(\"✅ Short-term memory cleared. Long-term memory persists in ChromaDB.\")\n    else:\n        print(\"❌ Operation cancelled\")\n\ndef export_conversation_history():\n    \"\"\"Export current conversation to dict\"\"\"\n    history = memory_manager.get_recent_history()\n    print(f\"\\n📤 Exporting {len(history)} exchanges...\")\n    return history\n\n# Demo usage\nif 'memory_manager' in globals():\n    show_memory_stats()\n    print(\"\\n\" + \"=\"*50)\n    print(\"Available utilities:\")\n    print(\"  - show_memory_stats()\")\n    print(\"  - search_memory('your query', n=3)\")\n    print(\"  - clear_all_memory()\")\n    print(\"  - export_conversation_history()\")\nelse:\n    print(\"❌ Memory Manager not initialized\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:02:51.879045Z","iopub.execute_input":"2026-01-15T18:02:51.879745Z","iopub.status.idle":"2026-01-15T18:02:51.891265Z","shell.execute_reply.started":"2026-01-15T18:02:51.879718Z","shell.execute_reply":"2026-01-15T18:02:51.890468Z"}},"outputs":[{"name":"stdout","text":"📊 MEMORY SYSTEM STATISTICS\n==================================================\n\n🧠 SHORT-TERM MEMORY:\n   - Buffer size: 1/10\n   - Capacity: 10.0%\n\n🗄️ LONG-TERM MEMORY:\n   - Stored conversations: 1\n   - Extracted facts: 0\n   - Total persistent records: 1\n\n==================================================\nAvailable utilities:\n  - show_memory_stats()\n  - search_memory('your query', n=3)\n  - clear_all_memory()\n  - export_conversation_history()\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# 🧠 MEMORY-AUGMENTED MULTI-TURN CONVERSATION TEST\nprint(\"🚀 Starting Memory-Augmented Conversation Demo...\\n\")\n\nif 'app' in globals() and 'engine' in globals() and 'memory_manager' in globals():\n    \n    # Test conversation flow that demonstrates memory\n    conversation_flow = [\n        \"What is the trend of attrition rate over the last 3 years?\",\n        \"Can you elaborate on the first point you mentioned?\",  # Memory reference\n        \"What about revenue distribution across geographies?\",\n        \"How does that compare to what you said earlier about attrition?\",  # Cross-reference\n        \"Summarize everything we've discussed so far\"  # Memory synthesis\n    ]\n    \n    for i, q in enumerate(conversation_flow, 1):\n        print(f\"\\n{'='*60}\")\n        print(f\"❓ Question {i}: {q}\")\n        print('='*60)\n        \n        try:\n            # Invoke the Agent\n            res = app.invoke({\n                \"question\": q,\n                \"retries\": 0,\n                \"memory_context\": \"\",\n                \"long_term_memory\": \"\",\n                \"should_store_memory\": False\n            })\n            \n            answer = res.get(\"generation\", \"No answer generated.\")\n            \n            print(f\"\\n✅ Agent Answer:\\n{answer}\")\n            \n            # Show memory state after each exchange\n            print(f\"\\n📊 Memory Status:\")\n            print(f\"   - Short-term buffer: {len(memory_manager.conversation_buffer)} exchanges\")\n            print(f\"   - Memory stored: {'✓' if res.get('should_store_memory') else '✗'}\")\n            \n        except Exception as e:\n            print(f\"❌ Error: {e}\")\n        \n        print(\"\\n\" + \"-\"*60)\n    \n    # Final memory summary\n    print(\"\\n\" + \"=\"*60)\n    print(\"📚 FINAL MEMORY SUMMARY\")\n    print(\"=\"*60)\n    print(f\"\\n🧠 Short-Term Memory ({len(memory_manager.conversation_buffer)} exchanges):\")\n    for idx, exch in enumerate(memory_manager.get_recent_history(), 1):\n        print(f\"\\n[{idx}] Q: {exch['question']}\")\n        print(f\"    A: {exch['answer'][:100]}...\")\n    \nelse:\n    print(\"❌ Agent app, Engine, or Memory Manager not found. Please ensure previous cells were run successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:04:00.101430Z","iopub.execute_input":"2026-01-15T18:04:00.101716Z","iopub.status.idle":"2026-01-15T18:09:23.033281Z","shell.execute_reply.started":"2026-01-15T18:04:00.101692Z","shell.execute_reply":"2026-01-15T18:09:23.032575Z"}},"outputs":[{"name":"stdout","text":"🚀 Starting Memory-Augmented Conversation Demo...\n\n\n============================================================\n❓ Question 1: What is the trend of attrition rate over the last 3 years?\n============================================================\n🧠 Retrieving Relevant Memories...\n🔍 Hybrid Retrieval for: 'What is the trend of attrition rate over the last 3 years?'\n📝 Grading Retrieval Quality...\n💡 Generating Answer with Memory Context...\n🛡️ Verifying Grounding...\n💾 Storing to Memory...\n\n✅ Agent Answer:\nI found some documents, but the answer I generated couldn't be fully verified against them.\n\n📊 Memory Status:\n   - Short-term buffer: 4 exchanges\n   - Memory stored: ✗\n\n------------------------------------------------------------\n\n============================================================\n❓ Question 2: Can you elaborate on the first point you mentioned?\n============================================================\n🧠 Retrieving Relevant Memories...\n🔍 Hybrid Retrieval for: 'Can you elaborate on the first point you mentioned?'\n📝 Grading Retrieval Quality...\n💡 Generating Answer with Memory Context...\n🛡️ Verifying Grounding...\n💾 Storing to Memory...\n   ✅ Memory stored successfully\n\n✅ Agent Answer:\nThis conversation has just begun. I haven't mentioned any points prior to your question. If you'd like to discuss something specific from the document context or conversation history, I'm here to help. Please feel free to ask, and I'll do my best to provide a concise and accurate answer.\n\n📊 Memory Status:\n   - Short-term buffer: 5 exchanges\n   - Memory stored: ✓\n\n------------------------------------------------------------\n\n============================================================\n❓ Question 3: What about revenue distribution across geographies?\n============================================================\n🧠 Retrieving Relevant Memories...\n🔍 Hybrid Retrieval for: 'What about revenue distribution across geographies?'\n📝 Grading Retrieval Quality...\n💡 Generating Answer with Memory Context...\n🛡️ Verifying Grounding...\n💾 Storing to Memory...\n   ✅ Memory stored successfully\n\n✅ Agent Answer:\nThe revenue distribution across geographies is as follows: \n- United States of America (USA): 58.1% (₹67,987 crores)\n- Europe: 26.7% (₹31,240 crores)\n- India: 3.1% (₹3,667 crores)\n- Rest of the world: 12.1% (₹14,161 crores)\n\nThis information is based on the year ended 31 March 2025.\n\n📊 Memory Status:\n   - Short-term buffer: 6 exchanges\n   - Memory stored: ✓\n\n------------------------------------------------------------\n\n============================================================\n❓ Question 4: How does that compare to what you said earlier about attrition?\n============================================================\n🧠 Retrieving Relevant Memories...\n🔍 Hybrid Retrieval for: 'How does that compare to what you said earlier about attrition?'\n📝 Grading Retrieval Quality...\n🔄 Retrieval Poor. Rewriting Query...\n   -> New Query: 'attrition comparison earlier vector database'\n🔍 Hybrid Retrieval for: 'attrition comparison earlier vector database'\n📝 Grading Retrieval Quality...\n💡 Generating Answer with Memory Context...\n🛡️ Verifying Grounding...\n💾 Storing to Memory...\n   ✅ Memory stored successfully\n\n✅ Agent Answer:\nThe document context does not provide a direct comparison of attrition rates. However, it mentions that HCLTech faces the risk of higher attrition rates, which could affect delivery capability and growth plans. To mitigate this risk, the company has implemented various initiatives to attract, engage, and retain a stable, diverse, and multi-generational employee pool. \n\nThere is no mention of an \"earlier vector database\" in the document context or conversation history. If you could provide more context or clarify the question, I'll be happy to help.\n\n📊 Memory Status:\n   - Short-term buffer: 7 exchanges\n   - Memory stored: ✓\n\n------------------------------------------------------------\n\n============================================================\n❓ Question 5: Summarize everything we've discussed so far\n============================================================\n🧠 Retrieving Relevant Memories...\n🔍 Hybrid Retrieval for: 'Summarize everything we've discussed so far'\n📝 Grading Retrieval Quality...\n💡 Generating Answer with Memory Context...\n🛡️ Verifying Grounding...\n💾 Storing to Memory...\n\n✅ Agent Answer:\nI found some documents, but the answer I generated couldn't be fully verified against them.\n\n📊 Memory Status:\n   - Short-term buffer: 7 exchanges\n   - Memory stored: ✗\n\n------------------------------------------------------------\n\n============================================================\n📚 FINAL MEMORY SUMMARY\n============================================================\n\n🧠 Short-Term Memory (7 exchanges):\n\n[1] Q: What is the consolidated revenue growth?\n    A: The consolidated revenue growth is 6.5%, with revenue from operations increasing to ₹117,055 crores ...\n\n[2] Q: What is the company revenue?\n    A: Total revenue is $500M in FY24...\n\n[3] Q: How about profit margins?\n    A: Net profit margin is 15%...\n\n[4] Q: What are growth projections?\n    A: Projected 20% YoY growth for next 3 years...\n\n[5] Q: Can you elaborate on the first point you mentioned?\n    A: This conversation has just begun. I haven't mentioned any points prior to your question. If you'd li...\n\n[6] Q: What about revenue distribution across geographies?\n    A: The revenue distribution across geographies is as follows: \n- United States of America (USA): 58.1% ...\n\n[7] Q: How does that compare to what you said earlier about attrition?\n    A: The document context does not provide a direct comparison of attrition rates. However, it mentions t...\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# 🎨 VISUAL MEMORY FLOW DEMO\n# Run this cell to see the complete memory lifecycle in action\n\ndef demo_memory_lifecycle():\n    \"\"\"\n    Demonstrates the complete memory lifecycle with visual feedback\n    \"\"\"\n    print(\"╔\" + \"=\"*60 + \"╗\")\n    print(\"║\" + \" \"*15 + \"MEMORY LIFECYCLE DEMO\" + \" \"*24 + \"║\")\n    print(\"╚\" + \"=\"*60 + \"╝\\n\")\n    \n    if 'memory_manager' not in globals():\n        print(\"❌ Memory Manager not initialized. Run previous cells first.\")\n        return\n    \n    # Step 1: Show initial state\n    print(\"📊 STEP 1: Initial Memory State\")\n    print(\"-\" * 60)\n    print(f\"   Short-term buffer: {len(memory_manager.conversation_buffer)} exchanges\")\n    print(f\"   Long-term storage: {memory_manager.memory_collection.count()} records\")\n    \n    # Step 2: Simulate adding memories\n    print(\"\\n💾 STEP 2: Adding Sample Exchanges to Short-Term\")\n    print(\"-\" * 60)\n    sample_exchanges = [\n        (\"What is the company revenue?\", \"Total revenue is $500M in FY24\"),\n        (\"How about profit margins?\", \"Net profit margin is 15%\"),\n        (\"What are growth projections?\", \"Projected 20% YoY growth for next 3 years\")\n    ]\n    \n    for q, a in sample_exchanges:\n        memory_manager.add_exchange(q, a, {\"demo\": True})\n        print(f\"   ✓ Added: Q: {q[:40]}...\")\n    \n    print(f\"\\n   Buffer now contains: {len(memory_manager.conversation_buffer)} exchanges\")\n    \n    # Step 3: Retrieve and format\n    print(\"\\n🔍 STEP 3: Retrieve Recent History (for LLM context)\")\n    print(\"-\" * 60)\n    formatted = memory_manager.format_history_for_prompt(n=3)\n    print(formatted)\n    \n    # Step 4: Store to long-term\n    print(\"\\n🗄️ STEP 4: Persist Important Exchange to Long-Term\")\n    print(\"-\" * 60)\n    mem_id = memory_manager.store_to_long_term(\n        question=sample_exchanges[0][0],\n        answer=sample_exchanges[0][1],\n        importance_score=0.85\n    )\n    print(f\"   ✓ Stored with ID: {mem_id[:16]}...\")\n    print(f\"   Long-term storage: {memory_manager.memory_collection.count()} records\")\n    \n    # Step 5: Semantic search\n    print(\"\\n🔎 STEP 5: Semantic Search Over Long-Term Memory\")\n    print(\"-\" * 60)\n    search_query = \"financial performance\"\n    print(f\"   Query: '{search_query}'\")\n    memories = memory_manager.retrieve_relevant_memories(search_query, n_results=2)\n    \n    if memories:\n        print(f\"   ✓ Found {len(memories)} relevant memories:\")\n        for i, mem in enumerate(memories, 1):\n            print(f\"\\n   [{i}] Q: {mem['question']}\")\n            print(f\"       A: {mem['answer'][:60]}...\")\n    else:\n        print(\"   (No matches - run after actual conversations)\")\n    \n    # Step 6: Consolidation\n    print(\"\\n♻️ STEP 6: Auto-Consolidation (when buffer full)\")\n    print(\"-\" * 60)\n    print(f\"   Current capacity: {len(memory_manager.conversation_buffer)}/{memory_manager.max_short_term}\")\n    print(f\"   Trigger point: {memory_manager.max_short_term - 1}\")\n    print(\"   Status: \" + (\"⚠️ Will consolidate soon\" if len(memory_manager.conversation_buffer) >= memory_manager.max_short_term - 2 else \"✅ Within limits\"))\n    \n    print(\"\\n\" + \"╔\" + \"=\"*60 + \"╗\")\n    print(\"║\" + \" \"*18 + \"LIFECYCLE COMPLETE\" + \" \"*24 + \"║\")\n    print(\"╚\" + \"=\"*60 + \"╝\\n\")\n    \n    print(\"💡 Key Takeaways:\")\n    print(\"   1. Short-term memory = Fast, recent context (in-memory)\")\n    print(\"   2. Long-term memory = Persistent, searchable (ChromaDB)\")\n    print(\"   3. Auto-consolidation prevents buffer overflow\")\n    print(\"   4. Semantic search enables intelligent context retrieval\")\n\n# Run the demo\ndemo_memory_lifecycle()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:03:13.115946Z","iopub.execute_input":"2026-01-15T18:03:13.116557Z","iopub.status.idle":"2026-01-15T18:03:13.174549Z","shell.execute_reply.started":"2026-01-15T18:03:13.116525Z","shell.execute_reply":"2026-01-15T18:03:13.173778Z"}},"outputs":[{"name":"stdout","text":"╔============================================================╗\n║               MEMORY LIFECYCLE DEMO                        ║\n╚============================================================╝\n\n📊 STEP 1: Initial Memory State\n------------------------------------------------------------\n   Short-term buffer: 1 exchanges\n   Long-term storage: 1 records\n\n💾 STEP 2: Adding Sample Exchanges to Short-Term\n------------------------------------------------------------\n   ✓ Added: Q: What is the company revenue?...\n   ✓ Added: Q: How about profit margins?...\n   ✓ Added: Q: What are growth projections?...\n\n   Buffer now contains: 4 exchanges\n\n🔍 STEP 3: Retrieve Recent History (for LLM context)\n------------------------------------------------------------\n[1] Q: What is the company revenue?\n    A: Total revenue is $500M in FY24...\n[2] Q: How about profit margins?\n    A: Net profit margin is 15%...\n[3] Q: What are growth projections?\n    A: Projected 20% YoY growth for next 3 years...\n\n🗄️ STEP 4: Persist Important Exchange to Long-Term\n------------------------------------------------------------\n   ✓ Stored with ID: e13503654c49b9b2...\n   Long-term storage: 2 records\n\n🔎 STEP 5: Semantic Search Over Long-Term Memory\n------------------------------------------------------------\n   Query: 'financial performance'\n   ✓ Found 2 relevant memories:\n\n   [1] Q: What is the consolidated revenue growth?\n       A: The consolidated revenue growth is 6.5%, with revenue from o...\n\n   [2] Q: What is the company revenue?\n       A: Total revenue is $500M in FY24...\n\n♻️ STEP 6: Auto-Consolidation (when buffer full)\n------------------------------------------------------------\n   Current capacity: 4/10\n   Trigger point: 9\n   Status: ✅ Within limits\n\n╔============================================================╗\n║                  LIFECYCLE COMPLETE                        ║\n╚============================================================╝\n\n💡 Key Takeaways:\n   1. Short-term memory = Fast, recent context (in-memory)\n   2. Long-term memory = Persistent, searchable (ChromaDB)\n   3. Auto-consolidation prevents buffer overflow\n   4. Semantic search enables intelligent context retrieval\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}